{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 90, 160, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 90, 160, 64)  1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 45, 80, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 45, 80, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 22, 40, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 22, 40, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 11, 20, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 14080)        0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14081)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           901248      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 976,961\n",
      "Trainable params: 976,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "459/459 [==============================] - 13s 11ms/step - loss: 0.0331 - MSE: 0.0331 - val_loss: 0.0138 - val_MSE: 0.0138\n",
      "Epoch 2/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0090 - MSE: 0.0090 - val_loss: 0.0114 - val_MSE: 0.0114\n",
      "Epoch 3/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0112 - val_MSE: 0.0112\n",
      "Epoch 4/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0117 - val_MSE: 0.0117\n",
      "Epoch 5/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0057 - MSE: 0.0057 - val_loss: 0.0107 - val_MSE: 0.0107\n",
      "Epoch 6/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 7/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 8/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0088 - val_MSE: 0.0088\n",
      "Epoch 9/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0103 - val_MSE: 0.0103\n",
      "Epoch 10/10\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0101 - val_MSE: 0.0101\n",
      "144/144 [==============================] - 1s 8ms/step\n",
      "Prediction min:  -0.5970035  Prediction max:  0.79195476\n"
     ]
    }
   ],
   "source": [
    "# First attempt to train a model based on images generated\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Conv2D, Concatenate, Embedding, Reshape, Flatten, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#constants to resize image to\n",
    "HEIGHT = 90\n",
    "WIDTH = 160\n",
    "\n",
    "\n",
    "YAW_ADJ_DEGREES = 35 # e.g. goes from -35 to +35\n",
    "\n",
    "\n",
    "#get a lsit of files\n",
    "mypath = 'C:/SelfDrive/GPS with Vision/_img'\n",
    "images = [f.split('.png')[0] for f in os.listdir(mypath) if f.endswith(\".png\")]\n",
    "\n",
    "random.shuffle(images)\n",
    "# get a list when both are available: image and steering\n",
    "\n",
    "# read training data \n",
    "\n",
    "X = [] #images\n",
    "X1 = [] # gen direction\n",
    "Y = [] #expected steering for this image\n",
    "for example in images:\n",
    "    img_path = mypath+'/'+example+'.png'\n",
    "    image = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "    # option to make images smaller\n",
    "    image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "    # this version adds taking lower side of the image\n",
    "    X.append(image / 255) # adding another dimension and normalising pixels to 0-1\n",
    "    # gen direction values are taken from after 1st '_' in file name\n",
    "    X1.append(int(example.split('_')[1]))\n",
    "    # y labels are taken from after 2nd '_' in file name\n",
    "    y = float(example.split('_')[2])\n",
    "    # convert to a fraction of 90 degrees so -1 is all the way left and + 1 is all the way right\n",
    "    if y >35:\n",
    "        y = 35\n",
    "    elif y<-35:\n",
    "        y = -35\n",
    "    \n",
    "    y = float(y)/YAW_ADJ_DEGREES # rescale to -1 to +1 so -1 is when max left 35degrees and +1 is +35deg\n",
    "    Y.append(y)\n",
    "\n",
    "#convert to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    \n",
    "    # Preprocess the image input\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Flatten()(processed_image)\n",
    "    \n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([processed_image, integer_input])\n",
    "    \n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu')(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['MSE'])\n",
    "\n",
    "\n",
    "model.fit([X, X1], Y, batch_size=16, shuffle=False, epochs=30, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict([X,X1])\n",
    "print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check distribution of our labels \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "frq, edges = np.histogram(Y, bins=20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(edges[:-1], frq, width=np.diff(edges), edgecolor=\"black\", align=\"edge\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This shows a clear inbalance of labels - the model will learn to go straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 90, 160, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 90, 160, 64)  1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 45, 80, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 45, 80, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 22, 40, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 22, 40, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 11, 20, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 14080)        0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14081)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           901248      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 976,961\n",
      "Trainable params: 976,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "536/536 [==============================] - 18s 17ms/step - loss: 14.7461 - MSE: 3145.3867 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 2/30\n",
      "536/536 [==============================] - 9s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 3/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 4/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 5/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 6/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 7/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 8/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 9/30\n",
      "536/536 [==============================] - 9s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 10/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 11/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 12/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 13/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 14/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 15/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 16/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 17/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 18/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 19/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 20/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 21/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 22/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 23/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 24/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 25/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 26/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 27/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 28/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 29/30\n",
      "536/536 [==============================] - 8s 15ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "Epoch 30/30\n",
      "536/536 [==============================] - 8s 16ms/step - loss: 14.7726 - MSE: 3286.4277 - val_loss: 14.7333 - val_MSE: 3297.1626\n",
      "335/335 [==============================] - 3s 8ms/step\n",
      "Prediction min:  4.887908  Prediction max:  71.72839\n"
     ]
    }
   ],
   "source": [
    "# Second attempt to train a model based on images generated\n",
    "# here we will try to weigh down over-represented \"drive straight\" images\n",
    "# I used weighted_binary_crossentropy function BUT it HAS NOT worked\n",
    "# probably because it is for classification rather than regression\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Conv2D, Concatenate, Embedding, Reshape, Flatten, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#constants to resize image to\n",
    "HEIGHT = 90\n",
    "WIDTH = 160\n",
    "\n",
    "\n",
    "YAW_ADJ_DEGREES = 35 # e.g. goes from -35 to +35\n",
    "\n",
    "\n",
    "#get a lsit of files\n",
    "mypath = 'C:/SelfDrive/GPS with Vision/_img'\n",
    "images = [f.split('.png')[0] for f in os.listdir(mypath) if f.endswith(\".png\")]\n",
    "\n",
    "random.shuffle(images)\n",
    "# get a list when both are available: image and steering\n",
    "\n",
    "# read training data \n",
    "\n",
    "X = [] #images\n",
    "X1 = [] # gen direction\n",
    "Y = [] #expected steering for this image\n",
    "for example in images:\n",
    "    img_path = mypath+'/'+example+'.png'\n",
    "    image = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "    # option to make images smaller\n",
    "    image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "    # this version adds taking lower side of the image\n",
    "    X.append(image / 255) # adding another dimension and normalising pixels to 0-1\n",
    "    # gen direction values are taken from after 1st '_' in file name\n",
    "    X1.append(int(example.split('_')[1]))\n",
    "    # y labels are taken from after 2nd '_' in file name\n",
    "    y = float(example.split('_')[2])\n",
    "    # convert to a fraction of 90 degrees so -1 is all the way left and + 1 is all the way right\n",
    "    if y >35:\n",
    "        y = 35\n",
    "    elif y<-35:\n",
    "        y = -35\n",
    "    \n",
    "    y = float(y)/YAW_ADJ_DEGREES # rescale to -1 to +1 so -1 is when max left 35degrees and +1 is +35deg\n",
    "    Y.append(y)\n",
    "\n",
    "#convert to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# this is a function I used before in semantic segmentation training\n",
    "def weighted_binary_crossentropy( y_true, y_pred, weight=1. ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean( logloss, axis=-1)\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    \n",
    "    # Preprocess the image input\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Flatten()(processed_image)\n",
    "    \n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([processed_image, integer_input])\n",
    "    \n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu')(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=weighted_binary_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['MSE'])\n",
    "\n",
    "\n",
    "model.fit([X, X1], Y, batch_size=16, shuffle=False, epochs=30, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict([X,X1])\n",
    "print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how training set is distributed:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 180, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 180, 320, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 90, 160, 64)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 90, 160, 64)  36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 45, 80, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 45, 80, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 22, 40, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 56320)        0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 56321)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           3604608     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,680,321\n",
      "Trainable params: 3,680,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# attempt 3\n",
    "# we will chop the training set limiting images with straight steering\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Conv2D, Concatenate, Embedding, Reshape, Flatten, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  \n",
    "\n",
    "#constants to resize image to\n",
    "HEIGHT = 180\n",
    "WIDTH = 320\n",
    "\n",
    "YAW_ADJ_DEGREES = 35 # e.g. goes from -35 to +35\n",
    "\n",
    "EVERY_WHAT = 5 # we will keep every n'th image with zero angle \n",
    "\n",
    "#get a lsit of files\n",
    "mypath = 'C:/SelfDrive/GPS with Vision/_img'\n",
    "images = [f.split('.png')[0] for f in os.listdir(mypath) if f.endswith(\".png\")]\n",
    "\n",
    "random.shuffle(images)\n",
    "\n",
    "X = [] #images\n",
    "X1 = [] # gen direction\n",
    "Y = [] #expected steering for this image\n",
    "straight_counter = 0 # we will be counting images to limit by applying \"every n'th\"\n",
    "for example in images:\n",
    "    img_path = mypath+'/'+example+'.png'\n",
    "    image = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "    # option to make images smaller\n",
    "    image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "    \n",
    "    # y labels are taken from after 2nd '_' in file name\n",
    "    y = float(example.split('_')[2])\n",
    "    # convert to a fraction of 90 degrees so -1 is all the way left and + 1 is all the way right\n",
    "    if y >35:\n",
    "        y = 35\n",
    "    elif y<-35:\n",
    "        y = -35\n",
    "    \n",
    "    y = float(y)/YAW_ADJ_DEGREES # rescale to -1 to +1 so -1 is when max left 35degrees and +1 is +35deg\n",
    "    # a rough balancing by reducing number of zero steer examples\n",
    "    if (abs(y)>0.05 or straight_counter % EVERY_WHAT ==0) and abs(y)<0.5:\n",
    "        X.append(image / 255) # adding another dimension and normalising pixels to 0-1\n",
    "        # gen direction values are taken from after 1st '_' in file name\n",
    "        X1.append(int(example.split('_')[1]))\n",
    "        Y.append(y)\n",
    "    if abs(y)>=0.05:\n",
    "        straight_counter +=1\n",
    "#convert to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "# draw how Y is distributed befored going into training\n",
    "frq, edges = np.histogram(Y, bins=20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(edges[:-1], frq, width=np.diff(edges), edgecolor=\"black\", align=\"edge\")\n",
    "print('This is how training set is distributed:')\n",
    "plt.show()\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    \n",
    "    # Preprocess the image input\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Flatten()(processed_image)\n",
    "    \n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([processed_image, integer_input])\n",
    "    \n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu')(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='MSE',\n",
    "              optimizer='adam',\n",
    "              metrics=['MSE'])\n",
    "\n",
    "\n",
    "#model.fit([X, X1], Y, batch_size=16, shuffle=False, epochs=30, validation_split=0.2)\n",
    "\n",
    "#predictions = model.predict([X,X1])\n",
    "#print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPS_Visual_Model_overfit\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPS_Visual_Model_overfit\\assets\n"
     ]
    }
   ],
   "source": [
    "# to save model\n",
    "model.save(\"GPS_Visual_Model_overfit\", overwrite=True,include_optimizer=True,\n",
    "    save_format=None, signatures=None, options=None, save_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 109. GiB for an array with shape (84518, 180, 320, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7872\\3185005601.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#convert to numpy arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 109. GiB for an array with shape (84518, 180, 320, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# attempt 4\n",
    "# we will balance the training set across steering angles and will only keep -0.5 to +0.5 examples\n",
    "\n",
    "# but this version runs out of memory\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Conv2D, Concatenate, Embedding, Reshape, Flatten, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  \n",
    "\n",
    "#constants to resize image to\n",
    "HEIGHT = 180\n",
    "WIDTH = 320\n",
    "\n",
    "YAW_ADJ_DEGREES = 35 # e.g. goes from -35 to +35\n",
    "\n",
    "def balance_array(bin_start,bin_end,bin_size):\n",
    "    '''\n",
    "    This function returns indicies of selected elements \n",
    "    which make the training set balanced\n",
    "    You need to apply the returned index to all training arrays  \n",
    "    '''\n",
    "    num_bins = int((bin_end - bin_start) / bin_size) + 1\n",
    "    min_count = np.min(np.histogram(Y, bins=num_bins, range=(bin_start, bin_end))[0])\n",
    "    balanced_array = []\n",
    "    selected = []\n",
    "\n",
    "    for start in np.arange(bin_start, bin_end, bin_size):\n",
    "        end = start + bin_size\n",
    "        indices = np.where((Y >= start) & (Y < end))[0]\n",
    "        #balanced_array.extend(Y[indices[:min_count]])\n",
    "        selected.extend(indices[:min_count])\n",
    "    return selected\n",
    "\n",
    "#get a lsit of files\n",
    "mypath = 'C:/SelfDrive/GPS with Vision/_img'\n",
    "images = [f.split('.png')[0] for f in os.listdir(mypath) if f.endswith(\".png\")]\n",
    "\n",
    "random.shuffle(images)\n",
    "\n",
    "X = [] #images\n",
    "X1 = [] # gen direction\n",
    "Y = [] #expected steering for this image\n",
    "for example in images:\n",
    "    img_path = mypath+'/'+example+'.png'\n",
    "    image = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "    # option to make images smaller\n",
    "    image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "    \n",
    "    # y labels are taken from after 2nd '_' in file name\n",
    "    y = float(example.split('_')[2])\n",
    "    # convert to a fraction of 90 degrees so -1 is all the way left and + 1 is all the way right\n",
    "    if y >35:\n",
    "        y = 35\n",
    "    elif y<-35:\n",
    "        y = -35\n",
    "    \n",
    "    y = float(y)/YAW_ADJ_DEGREES # rescale to -1 to +1 so -1 is when max left 35degrees and +1 is +35deg\n",
    "    # a rough balancing by reducing number of zero steer examples\n",
    "    X.append(image / 255) # adding another dimension and normalising pixels to 0-1\n",
    "    # gen direction values are taken from after 1st '_' in file name\n",
    "    X1.append(int(example.split('_')[1]))\n",
    "    Y.append(y)\n",
    "\n",
    "#convert to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "balanced_subset = balance_array(-0.5,0.5,0.05)\n",
    "\n",
    "X = X[balanced_subset]\n",
    "X1 = X1[balanced_subset]\n",
    "Y = Y[balanced_subset]\n",
    "\n",
    "# draw how Y is distributed befored going into training\n",
    "frq, edges = np.histogram(Y, bins=20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(edges[:-1], frq, width=np.diff(edges), edgecolor=\"black\", align=\"edge\")\n",
    "print('This is how training set is distributed:')\n",
    "plt.show()\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    \n",
    "    # Preprocess the image input\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "\n",
    "    processed_image = Flatten()(processed_image)\n",
    "    \n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([processed_image, integer_input])\n",
    "    \n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu')(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='MSE',\n",
    "              optimizer='adam',\n",
    "              metrics=['MSE'])\n",
    "\n",
    "\n",
    "model.fit([X, X1], Y, batch_size=16, shuffle=False, epochs=10, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict([X,X1])\n",
    "print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how training set is distributed:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 180, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 180, 320, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 90, 160, 64)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 90, 160, 64)  36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 45, 80, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 45, 80, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 22, 40, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 56320)        0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 56321)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           3604608     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,680,321\n",
      "Trainable params: 3,680,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "422/422 [==============================] - 477s 1s/step - loss: 0.0477 - MSE: 0.0477 - val_loss: 0.0166 - val_MSE: 0.0166\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 478s 1s/step - loss: 0.0103 - MSE: 0.0103 - val_loss: 0.0867 - val_MSE: 0.0867\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 480s 1s/step - loss: 0.0629 - MSE: 0.0629 - val_loss: 0.1341 - val_MSE: 0.1341\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 455s 1s/step - loss: 0.0550 - MSE: 0.0550 - val_loss: 0.1439 - val_MSE: 0.1439\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 446s 1s/step - loss: 0.0539 - MSE: 0.0539 - val_loss: 0.1474 - val_MSE: 0.1474\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 441s 1s/step - loss: 0.0536 - MSE: 0.0536 - val_loss: 0.1490 - val_MSE: 0.1490\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 434s 1s/step - loss: 0.0535 - MSE: 0.0535 - val_loss: 0.1500 - val_MSE: 0.1500\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 428s 1s/step - loss: 0.0535 - MSE: 0.0535 - val_loss: 0.1505 - val_MSE: 0.1505\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 442s 1s/step - loss: 0.0535 - MSE: 0.0535 - val_loss: 0.1509 - val_MSE: 0.1509\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 441s 1s/step - loss: 0.0534 - MSE: 0.0534 - val_loss: 0.1511 - val_MSE: 0.1511\n",
      "264/264 [==============================] - 110s 416ms/step\n",
      "Prediction min:  -0.0011058366  Prediction max:  0.008240545\n"
     ]
    }
   ],
   "source": [
    "# attempt 5\n",
    "# we will exclude most of zero steer examples before we add examples to our arrays\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Conv2D, Concatenate, Embedding, Reshape, Flatten, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "\n",
    "#disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  \n",
    "\n",
    "#constants to resize image to\n",
    "HEIGHT = 180\n",
    "WIDTH = 320\n",
    "\n",
    "YAW_ADJ_DEGREES = 35 # e.g. goes from -35 to +35\n",
    "\n",
    "EVERY_WHAT = 7\n",
    "\n",
    "def balance_array(bin_start,bin_end,bin_size):\n",
    "    '''\n",
    "    This function returns indicies of selected elements \n",
    "    which make the training set balanced\n",
    "    You need to apply the returned index to all training arrays  \n",
    "    '''\n",
    "    num_bins = int((bin_end - bin_start) / bin_size) + 1\n",
    "    min_count = np.min(np.histogram(Y, bins=num_bins, range=(bin_start, bin_end))[0])\n",
    "    balanced_array = []\n",
    "    selected = []\n",
    "\n",
    "    for start in np.arange(bin_start, bin_end, bin_size):\n",
    "        end = start + bin_size\n",
    "        indices = np.where((Y >= start) & (Y < end))[0]\n",
    "        #balanced_array.extend(Y[indices[:min_count]])\n",
    "        selected.extend(indices[:min_count])\n",
    "    return selected\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    # Preprocess the image input\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "    processed_image = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(processed_image)\n",
    "    processed_image = MaxPooling2D(pool_size=(2, 2))(processed_image)\n",
    "    processed_image = Flatten()(processed_image)\n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([processed_image, integer_input])\n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu')(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "#get a lsit of files\n",
    "mypath = 'C:/SelfDrive/GPS with Vision/_img'\n",
    "images = [f.split('.png')[0] for f in os.listdir(mypath) if f.endswith(\".png\")]\n",
    "\n",
    "random.shuffle(images)\n",
    "\n",
    "X = [] #images\n",
    "X1 = [] # gen direction\n",
    "Y = [] #expected steering for this image\n",
    "straight_counter = 0 # we will be counting images to limit by applying \"every n'th\"\n",
    "for example in images:\n",
    "    img_path = mypath+'/'+example+'.png'\n",
    "    image = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "    # option to make images smaller\n",
    "    image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "    \n",
    "    # y labels are taken from after 2nd '_' in file name\n",
    "    y = float(example.split('_')[2])\n",
    "    # convert to a fraction of 90 degrees so -1 is all the way left and + 1 is all the way right\n",
    "    if y >35:\n",
    "        y = 35\n",
    "    elif y<-35:\n",
    "        y = -35\n",
    "    \n",
    "    y = float(y)/YAW_ADJ_DEGREES # rescale to -1 to +1 so -1 is when max left 35degrees and +1 is +35deg\n",
    "    if (abs(y)>0.05 or straight_counter % EVERY_WHAT ==0) and abs(y)<0.5:\n",
    "        X.append(image / 255) # adding another dimension and normalising pixels to 0-1\n",
    "        # gen direction values are taken from after 1st '_' in file name\n",
    "        X1.append(int(example.split('_')[1]))\n",
    "        Y.append(y)\n",
    "    if abs(y)>=0.05:\n",
    "        straight_counter +=1\n",
    "\n",
    "#convert to numpy arrays\n",
    "X = np.array(X)\n",
    "X1 = np.array(X1)\n",
    "Y = np.array(Y)\n",
    "\n",
    "balanced_subset = balance_array(-0.5,0.5,0.05)\n",
    "\n",
    "X = X[balanced_subset]\n",
    "X1 = X1[balanced_subset]\n",
    "Y = Y[balanced_subset]\n",
    "\n",
    "# draw how Y is distributed befored going into training\n",
    "frq, edges = np.histogram(Y, bins=20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(edges[:-1], frq, width=np.diff(edges), edgecolor=\"black\", align=\"edge\")\n",
    "print('This is how training set is distributed:')\n",
    "plt.show()\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='MSE',\n",
    "              optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit([X, X1], Y, batch_size=16, shuffle=False, epochs=10, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict([X,X1])\n",
    "print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "106/106 [==============================] - 438s 4s/step - loss: 0.0627 - MSE: 0.0627 - val_loss: 0.1792 - val_MSE: 0.1792\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 437s 4s/step - loss: 0.0560 - MSE: 0.0560 - val_loss: 0.2070 - val_MSE: 0.2070\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 435s 4s/step - loss: 0.0534 - MSE: 0.0534 - val_loss: 0.2260 - val_MSE: 0.2260\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 435s 4s/step - loss: 0.0525 - MSE: 0.0525 - val_loss: 0.2369 - val_MSE: 0.2369\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 446s 4s/step - loss: 0.0522 - MSE: 0.0522 - val_loss: 0.2442 - val_MSE: 0.2442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17158e0a508>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, X1], Y, batch_size=64, shuffle=True, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 180, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 180, 320, 64  1792        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 90, 160, 64)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 90, 160, 64)  36928       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 45, 80, 64)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 45, 80, 64)   36928       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 22, 40, 64)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 56320)        0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56321)        0           ['flatten_1[0][0]',              \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           3604608     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            65          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,680,321\n",
      "Trainable params: 3,680,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "211/211 [==============================] - 523s 2s/step - loss: 0.4639 - val_loss: 0.0893\n",
      "Epoch 2/5\n",
      "211/211 [==============================] - 521s 2s/step - loss: 0.0485 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "211/211 [==============================] - 530s 3s/step - loss: 0.0286 - val_loss: 0.0367\n",
      "Epoch 4/5\n",
      "211/211 [==============================] - 523s 2s/step - loss: 0.0246 - val_loss: 0.0171\n",
      "Epoch 5/5\n",
      "211/211 [==============================] - 525s 2s/step - loss: 0.0214 - val_loss: 0.0152\n",
      "264/264 [==============================] - 111s 421ms/step\n",
      "Prediction min:  0.27616963  Prediction max:  0.3254479\n"
     ]
    }
   ],
   "source": [
    "# creating a version with regularisers\n",
    "from keras import regularizers\n",
    "# adding batch norm\n",
    "def create_model():\n",
    "    # Image input\n",
    "    image_input = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    # Integer input\n",
    "    integer_input = Input(shape=(1,))\n",
    "    # Preprocess the image input\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same',activity_regularizer=regularizers.L2(1e-5))(image_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same',activity_regularizer=regularizers.L2(1e-5))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same',activity_regularizer=regularizers.L2(1e-5))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    # Concatenate image features with integer input\n",
    "    concatenated_inputs = Concatenate()([x, integer_input])\n",
    "    # Dense layers for prediction\n",
    "    x = Dense(64, activation='relu',activity_regularizer=regularizers.L2(1e-5))(concatenated_inputs)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "    # Create the model\n",
    "    model = Model(inputs=[image_input, integer_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model.compile(loss='MSE',\n",
    "              optimizer='adam')\n",
    "model.fit([X, X1], Y, batch_size=32, shuffle=False, epochs=5, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict([X,X1])\n",
    "print(\"Prediction min: \",predictions.min(),\" Prediction max: \",predictions.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
